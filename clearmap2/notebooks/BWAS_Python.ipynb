{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BWAS_Python\n",
    "In this notebook, I go through an example of how to do Brain-wide association studies (BWAS) in Python. In particular, to compare c-fos cell counts across multiple brain regions across treatment groups. I use two methods: linear regression and negative binomial regression.\n",
    "\n",
    "This is an attempt to reproduce the results by Will Townes performed in R for Jess Verpeut's 2021 Cell Reports paper. See his (potentially still private) repo: https://github.com/willtownes/neuro (contact at ftownes@princeton.edu).\n",
    "\n",
    "**NB:** For linear regression, the results are nearly identical between Python and R. For negative binomial regression, the standard error estimates are quite different between Python and R. The estimates themselves are relatively consistent, however. A detailed comparison between these two methods has not been done, nor is it well understood.\n",
    "\n",
    "- Author: Austin Hoag (with massive help from Will Townes)\n",
    "- Date: August 25, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from patsy import dmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using whole-brain c-fos cell counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/Jess_cfos_total_and_fractional_counts-total_122_regions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brain</th>\n",
       "      <th>batch</th>\n",
       "      <th>condition</th>\n",
       "      <th>Anterior amygdalar area</th>\n",
       "      <th>Basolateral amygdalar nucleus</th>\n",
       "      <th>Central amygdalar nucleus</th>\n",
       "      <th>Cortical amygdalar area</th>\n",
       "      <th>Intercalated amygdalar nucleus</th>\n",
       "      <th>Lateral amygdalar nucleus</th>\n",
       "      <th>Posterior amygdalar nucleus</th>\n",
       "      <th>...</th>\n",
       "      <th>Supragenual nucleus</th>\n",
       "      <th>Supratrigeminal nucleus</th>\n",
       "      <th>Tegmental reticular nucleus</th>\n",
       "      <th>Motor nucleus of trigeminal</th>\n",
       "      <th>Laterodorsal tegmental nucleus</th>\n",
       "      <th>Nucleus incertus</th>\n",
       "      <th>Pontine reticular nucleus</th>\n",
       "      <th>Nucleus raphe pontis</th>\n",
       "      <th>Subceruleus nucleus</th>\n",
       "      <th>Sublaterodorsal nucleus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an011</td>\n",
       "      <td>202010_cfos</td>\n",
       "      <td>acquisition_day1</td>\n",
       "      <td>156</td>\n",
       "      <td>2173</td>\n",
       "      <td>2163</td>\n",
       "      <td>736</td>\n",
       "      <td>160</td>\n",
       "      <td>601</td>\n",
       "      <td>293</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>223</td>\n",
       "      <td>137</td>\n",
       "      <td>221</td>\n",
       "      <td>95</td>\n",
       "      <td>619</td>\n",
       "      <td>31</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an012</td>\n",
       "      <td>202010_cfos</td>\n",
       "      <td>acquisition_day1</td>\n",
       "      <td>350</td>\n",
       "      <td>2327</td>\n",
       "      <td>1595</td>\n",
       "      <td>781</td>\n",
       "      <td>224</td>\n",
       "      <td>816</td>\n",
       "      <td>292</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>165</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "      <td>36</td>\n",
       "      <td>870</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>an013</td>\n",
       "      <td>202010_cfos</td>\n",
       "      <td>acquisition_day1</td>\n",
       "      <td>569</td>\n",
       "      <td>2517</td>\n",
       "      <td>1224</td>\n",
       "      <td>824</td>\n",
       "      <td>153</td>\n",
       "      <td>704</td>\n",
       "      <td>521</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>365</td>\n",
       "      <td>183</td>\n",
       "      <td>221</td>\n",
       "      <td>85</td>\n",
       "      <td>834</td>\n",
       "      <td>111</td>\n",
       "      <td>93</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an014</td>\n",
       "      <td>202010_cfos</td>\n",
       "      <td>acquisition_day1</td>\n",
       "      <td>688</td>\n",
       "      <td>2051</td>\n",
       "      <td>1224</td>\n",
       "      <td>523</td>\n",
       "      <td>169</td>\n",
       "      <td>1076</td>\n",
       "      <td>514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>224</td>\n",
       "      <td>143</td>\n",
       "      <td>157</td>\n",
       "      <td>106</td>\n",
       "      <td>864</td>\n",
       "      <td>120</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an015</td>\n",
       "      <td>202010_cfos</td>\n",
       "      <td>acquisition_day1</td>\n",
       "      <td>150</td>\n",
       "      <td>1452</td>\n",
       "      <td>608</td>\n",
       "      <td>330</td>\n",
       "      <td>100</td>\n",
       "      <td>417</td>\n",
       "      <td>304</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>272</td>\n",
       "      <td>119</td>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>660</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>dadult_pc_crus1_1</td>\n",
       "      <td>201810_adultacutePC_ymaze_cfos</td>\n",
       "      <td>vector_control_reversal</td>\n",
       "      <td>131</td>\n",
       "      <td>311</td>\n",
       "      <td>264</td>\n",
       "      <td>300</td>\n",
       "      <td>18</td>\n",
       "      <td>167</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>dadult_pc_crus1_3</td>\n",
       "      <td>201810_adultacutePC_ymaze_cfos</td>\n",
       "      <td>vector_control_reversal</td>\n",
       "      <td>123</td>\n",
       "      <td>512</td>\n",
       "      <td>298</td>\n",
       "      <td>494</td>\n",
       "      <td>19</td>\n",
       "      <td>113</td>\n",
       "      <td>243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>dadult_pc_crus1_4</td>\n",
       "      <td>201810_adultacutePC_ymaze_cfos</td>\n",
       "      <td>vector_control_reversal</td>\n",
       "      <td>99</td>\n",
       "      <td>279</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "      <td>91</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>dadult_pc_lob6_14</td>\n",
       "      <td>201810_adultacutePC_ymaze_cfos</td>\n",
       "      <td>vector_control_reversal</td>\n",
       "      <td>69</td>\n",
       "      <td>711</td>\n",
       "      <td>281</td>\n",
       "      <td>363</td>\n",
       "      <td>28</td>\n",
       "      <td>175</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>dadult_pc_lob6_16</td>\n",
       "      <td>201810_adultacutePC_ymaze_cfos</td>\n",
       "      <td>vector_control_reversal</td>\n",
       "      <td>88</td>\n",
       "      <td>198</td>\n",
       "      <td>106</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows Ã— 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 brain                           batch  \\\n",
       "0                an011                     202010_cfos   \n",
       "1                an012                     202010_cfos   \n",
       "2                an013                     202010_cfos   \n",
       "3                an014                     202010_cfos   \n",
       "4                an015                     202010_cfos   \n",
       "..                 ...                             ...   \n",
       "164  dadult_pc_crus1_1  201810_adultacutePC_ymaze_cfos   \n",
       "165  dadult_pc_crus1_3  201810_adultacutePC_ymaze_cfos   \n",
       "166  dadult_pc_crus1_4  201810_adultacutePC_ymaze_cfos   \n",
       "167  dadult_pc_lob6_14  201810_adultacutePC_ymaze_cfos   \n",
       "168  dadult_pc_lob6_16  201810_adultacutePC_ymaze_cfos   \n",
       "\n",
       "                   condition  Anterior amygdalar area  \\\n",
       "0           acquisition_day1                      156   \n",
       "1           acquisition_day1                      350   \n",
       "2           acquisition_day1                      569   \n",
       "3           acquisition_day1                      688   \n",
       "4           acquisition_day1                      150   \n",
       "..                       ...                      ...   \n",
       "164  vector_control_reversal                      131   \n",
       "165  vector_control_reversal                      123   \n",
       "166  vector_control_reversal                       99   \n",
       "167  vector_control_reversal                       69   \n",
       "168  vector_control_reversal                       88   \n",
       "\n",
       "     Basolateral amygdalar nucleus  Central amygdalar nucleus  \\\n",
       "0                             2173                       2163   \n",
       "1                             2327                       1595   \n",
       "2                             2517                       1224   \n",
       "3                             2051                       1224   \n",
       "4                             1452                        608   \n",
       "..                             ...                        ...   \n",
       "164                            311                        264   \n",
       "165                            512                        298   \n",
       "166                            279                        142   \n",
       "167                            711                        281   \n",
       "168                            198                        106   \n",
       "\n",
       "     Cortical amygdalar area  Intercalated amygdalar nucleus  \\\n",
       "0                        736                             160   \n",
       "1                        781                             224   \n",
       "2                        824                             153   \n",
       "3                        523                             169   \n",
       "4                        330                             100   \n",
       "..                       ...                             ...   \n",
       "164                      300                              18   \n",
       "165                      494                              19   \n",
       "166                      143                               4   \n",
       "167                      363                              28   \n",
       "168                        5                              12   \n",
       "\n",
       "     Lateral amygdalar nucleus  Posterior amygdalar nucleus  ...  \\\n",
       "0                          601                          293  ...   \n",
       "1                          816                          292  ...   \n",
       "2                          704                          521  ...   \n",
       "3                         1076                          514  ...   \n",
       "4                          417                          304  ...   \n",
       "..                         ...                          ...  ...   \n",
       "164                        167                          109  ...   \n",
       "165                        113                          243  ...   \n",
       "166                         91                           40  ...   \n",
       "167                        175                          104  ...   \n",
       "168                         68                           24  ...   \n",
       "\n",
       "     Supragenual nucleus  Supratrigeminal nucleus  \\\n",
       "0                      0                      263   \n",
       "1                      0                       98   \n",
       "2                      0                      235   \n",
       "3                      0                      149   \n",
       "4                      0                      144   \n",
       "..                   ...                      ...   \n",
       "164                    0                        0   \n",
       "165                    0                        0   \n",
       "166                    0                        0   \n",
       "167                    0                        0   \n",
       "168                    0                       26   \n",
       "\n",
       "     Tegmental reticular nucleus  Motor nucleus of trigeminal  \\\n",
       "0                            223                          137   \n",
       "1                            165                          225   \n",
       "2                            365                          183   \n",
       "3                            224                          143   \n",
       "4                            272                          119   \n",
       "..                           ...                          ...   \n",
       "164                            0                            0   \n",
       "165                            0                            0   \n",
       "166                            0                            0   \n",
       "167                            0                            0   \n",
       "168                            0                            0   \n",
       "\n",
       "     Laterodorsal tegmental nucleus  Nucleus incertus  \\\n",
       "0                               221                95   \n",
       "1                               166                36   \n",
       "2                               221                85   \n",
       "3                               157               106   \n",
       "4                               149                51   \n",
       "..                              ...               ...   \n",
       "164                              15                 0   \n",
       "165                               0                 0   \n",
       "166                               0                 0   \n",
       "167                               0                 0   \n",
       "168                               0                 0   \n",
       "\n",
       "     Pontine reticular nucleus  Nucleus raphe pontis  Subceruleus nucleus  \\\n",
       "0                          619                    31                   54   \n",
       "1                          870                    45                   14   \n",
       "2                          834                   111                   93   \n",
       "3                          864                   120                   17   \n",
       "4                          660                    56                   25   \n",
       "..                         ...                   ...                  ...   \n",
       "164                        142                     0                    0   \n",
       "165                        110                     0                    0   \n",
       "166                          3                     0                    0   \n",
       "167                          0                     0                    0   \n",
       "168                         37                     0                    0   \n",
       "\n",
       "     Sublaterodorsal nucleus  \n",
       "0                         40  \n",
       "1                         31  \n",
       "2                         64  \n",
       "3                         50  \n",
       "4                        208  \n",
       "..                       ...  \n",
       "164                        0  \n",
       "165                        0  \n",
       "166                        0  \n",
       "167                        0  \n",
       "168                        0  \n",
       "\n",
       "[169 rows x 125 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split predictor variables (batch, condition) from count information\n",
    "all_predictors = df[['batch','condition']]\n",
    "all_counts = df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: CNO_control_reversal (control) vs. CNOnCrusILT (treatment)\n",
    "\n",
    "The null hypothesis is that c-fos counts are drawn from the same distribution in both of these groups, across all brain regions. We can test this on individual brain regions and also across all brain regions. If doing the latter, we must control for false discovery rate, which we can do with the Benjamini-Hochberg method (see below).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all entries from either conditon\n",
    "condition1 = 'CNO_control_reversal'\n",
    "condition2 = 'CNOnCrusILT'\n",
    "condition_mask = (all_predictors['condition']==condition1) | (all_predictors['condition']==condition2)\n",
    "predictors = all_predictors.loc[condition_mask,:]\n",
    "counts = all_counts.loc[condition_mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see that we have 3 batches here and 2 conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Paty's neat dmatrix() function to create the \"design matrix\"\n",
    "# This converts the batch and condition values which are categorical in nature\\\n",
    "# into numeric values\n",
    "# \n",
    "# We only need to do this once per batch/condition combo \n",
    "design_matrix = dmatrix(\"batch + condition\", predictors,return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there are only two batch columns but we started with three batches. That is because If both batch columns here are 0 then the membership is to the third batch. Also note the intercept column which was automatically added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the test for an example brain region\n",
    "brain_regions = subdf.columns[3:]\n",
    "brain_region = brain_regions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(pd.concat([predictors,counts],axis=1), x=brain_region, hue=\"condition\",binwidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the fractional counts in this brain region\n",
    "rowsums=np.sum(counts,axis=1)\n",
    "counts_thisregion = counts[brain_region]\n",
    "pcounts = counts_thisregion/rowsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the Linear Regression model and fit it\n",
    "mod = sm.OLS(pcounts,design_matrix)\n",
    "res_LR = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a summary of the fit\n",
    "res_LR.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficient from the treatment regressor (the last one in the list)\n",
    "res_LR.params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the standard error from the treament regressor\n",
    "res_LR.bse[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-value from the treatment regressor\n",
    "res_LR.pvalues[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare results to using full Patsy formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply it to our case\n",
    "df_thisregion = pd.concat([pcounts,predictors],axis=1).rename(\n",
    "    columns={0:'AAA'})\n",
    "mod_fullformula = smf.ols(formula='AAA ~ batch + condition', data=df_thisregion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_fullformula = mod_fullformula.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_fullformula.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method gives the same results as the method where we precompute the design matrix. Because we will be running this regression for many brain regions and each region has the same predictors, we can use the same design matrix for all regressions. Therefore, it will be faster to use the first method so we will stick with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative binomial regression\n",
    "Here we use total counts instead of fractional counts but must calculate an offset which is the log of the row sums to include in the regression. Otherwise the inputs to the regression are the same. We can use that same design matrix.\n",
    "\n",
    "Here is a good explanation to help interpret the outputs of the model (see below): https://stats.idre.ucla.edu/sas/output/negative-binomial-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = np.log(rowsums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the negative binomial model and fit it\n",
    "nb_mod = sm.GLM(counts_thisregion, design_matrix,family=sm.families.NegativeBinomial(),offset=offsets)\n",
    "nb_fit = nb_mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a summary of the fit, you can extract the fit parameters in the exact same way\n",
    "# as we did for the linear model\n",
    "nb_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we get the same result as the full patsy formula\n",
    "# Now apply it to our case\n",
    "df_thisregion = pd.concat([counts_thisregion,predictors],axis=1).rename(\n",
    "    columns={'Anterior amygdalar area':'AAA'})\n",
    "nb_mod_fullformula = smf.glm(formula='AAA ~ batch + condition', data=df_thisregion,\n",
    "                         family=sm.families.NegativeBinomial(),offset=offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fit_fullformula = nb_mod_fullformula.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fit_fullformula.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we get the exact same results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbitrary conditions, looping over all brain regions\n",
    "Here we will write a function that can accept any two conditions and will run regressions over all brain regions for all animals in all batches of those two conditions.\n",
    "\n",
    "We will calculate adjusted p-values using the Benjamini-Hochberg method since we will be running N tests, where N is the number of brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bh_correction(p_values):\n",
    "    \"\"\" \n",
    "    ---DESCRIPTION---\n",
    "    Benjamini-Hochberg correction of p-values\n",
    "    This is not well tested. \n",
    "    ---INPUT---\n",
    "    p_values:           a list of p-values, can be unsorted but must not have nans\n",
    "    ---OUTPUT---\n",
    "    adjusted_p_values:  a list of adjusted p-values sorted from lowest to highest\n",
    "    \"\"\"\n",
    "    # sort the p-values\n",
    "    sorted_p_values = sorted(p_values)\n",
    "    # Make an empty array to fill in\n",
    "    adjusted_p_values = np.zeros_like(sorted_p_values)\n",
    "    # Fill them from highest to lowest\n",
    "    # First adjusted p-value is just highest p-value\n",
    "    adjusted_p_values[-1] = sorted_p_values[-1]\n",
    "    for p_value_index in range(len(sorted_p_values)-2,-1,-1):\n",
    "        next_highest = adjusted_p_values[p_value_index+1]\n",
    "        rank_current = p_value_index+1\n",
    "        mod_current = sorted_p_values[p_value_index] * (len(sorted_p_values)/rank_current)\n",
    "        adjusted_p_value = min(next_highest,mod_current)\n",
    "        adjusted_p_values[p_value_index] = adjusted_p_value\n",
    "    return adjusted_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(df,condition1,condition2):\n",
    "    \"\"\" \n",
    "    ---DESCRIPTION---\n",
    "    Perform linear regression between condition1 (assumed to be control) and\n",
    "    condition2 (assumed to be treatment). Uses all batches found in both conditions.\n",
    "    This is not well tested.\n",
    "    ---INPUT---\n",
    "    df:           an NxK dataframe where N rows are the animals and K are the columns, \n",
    "                  which must contain the batch, condition and counts in each brain region\n",
    "    condition1:   a string describing one of the conditions in the dataframe (the control)\n",
    "    condition2:   a string describing one of the conditions in the dataframe (the treatment)\n",
    "    ---OUTPUT--\n",
    "    lr_df:        A dataframe containing the results from the regression on all brain regions in df\n",
    "    Also Saves to a CSV file called: '../data/{condition1}-{condition2}-pcounts-linreg.csv'\n",
    "    \"\"\"\n",
    "    all_predictors = df[['batch','condition']]\n",
    "    all_counts = df.iloc[:,3:]\n",
    "    brain_regions = df.columns[3:]\n",
    "    \n",
    "    condition_mask = (all_predictors['condition']==condition1) | (all_predictors['condition']==condition2)\n",
    "    predictors = all_predictors.loc[condition_mask,:]\n",
    "    design_matrix = dmatrix(\"batch + condition\", predictors,return_type='dataframe')\n",
    "    counts = all_counts.loc[condition_mask,:]\n",
    "    rowsums=np.sum(counts,axis=1)\n",
    "    result_list = []\n",
    "    for ii in range(len(brain_regions)):\n",
    "        brain_region=brain_regions[ii]\n",
    "        result_dict = {\n",
    "            'region_idx':ii,\n",
    "            'control':condition1,\n",
    "            'treatment':condition2,\n",
    "            'region':brain_region\n",
    "        }\n",
    "        counts_thisregion = counts[brain_region]\n",
    "        pcounts = counts_thisregion/rowsums\n",
    "        res_LR = sm.OLS(pcounts,design_matrix).fit()\n",
    "        estimate = res_LR.params[-1]\n",
    "        stderr = res_LR.bse[-1]\n",
    "        pvalue = res_LR.pvalues[-1]\n",
    "        zscore = estimate/stderr\n",
    "        if np.isnan(zscore) or np.isnan(pvalue):\n",
    "            status=\"failed\"\n",
    "        else:\n",
    "            status=\"success\"\n",
    "        result_dict['Estimate'] = estimate\n",
    "        result_dict['Std. Error'] = stderr\n",
    "        result_dict['t value'] = zscore\n",
    "        result_dict['Pr(>|z|)'] = pvalue\n",
    "        result_dict['status'] = status\n",
    "        result_list.append(result_dict)\n",
    "    # Now calculate adjusted pvalues\n",
    "    # First sort the whole result_list by p-value, keeping in mind that there can be nans\n",
    "    sorted_result_list = sorted(result_list,\n",
    "            key=lambda x: float('-inf') if np.isnan(x.get('Pr(>|z|)')) else x.get('Pr(>|z|)')) \n",
    "    sorted_p_values = np.array([d.get('Pr(>|z|)') for d in sorted_result_list])\n",
    "    # separate out nans (which are at the beginning of the list due to how we sorted)\n",
    "    p_values_clean = sorted_p_values[~np.isnan(sorted_p_values)]\n",
    "    p_values_nan = sorted_p_values[np.isnan(sorted_p_values)]\n",
    "    # calculate the fdr adjusted p-values\n",
    "    adjusted_p_values_no_nans = bh_correction(p_values_clean)\n",
    "    # add back the nans to the beginning of the list\n",
    "    adj_p_values = np.concatenate([p_values_nan,adjusted_p_values_no_nans])\n",
    "    # add the fdr adjusted p-value into the list of our results\n",
    "    for ii in range(len(sorted_result_list)):\n",
    "        sorted_result_list[ii]['fdr_adj_pval'] = adj_p_values[ii]\n",
    "    # Finally, sort back to original order, the one using brain region index as key\n",
    "    final_result_list = sorted(sorted_result_list,key=lambda x: x.get('region_idx'))\n",
    "    # Make pandas dataframe to make it easier to save to file\n",
    "    lr_df = pd.DataFrame(final_result_list)\n",
    "    lr_df.set_index('region_idx',inplace=True)\n",
    "    # reorder columns\n",
    "    neworder = ['control','treatment','region','Estimate','Std. Error','t value','Pr(>|z|)','fdr_adj_pval','status']\n",
    "    lr_df=lr_df.reindex(columns=neworder)\n",
    "    # Save to csv\n",
    "    savename = f'../data/{condition1}-{condition2}-pcounts-linreg.csv'\n",
    "    lr_df.to_csv(savename,index=False)\n",
    "    print(f\"Saved {savename}\")\n",
    "    return lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../data/CNO_control_reversal-CNOnCrusILT-pcounts-linreg.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n",
      "<ipython-input-16-0d4154d7e782>:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  zscore = estimate/stderr\n"
     ]
    }
   ],
   "source": [
    "lr_df = linear_regression(df=df,condition1 = 'CNO_control_reversal',condition2 = 'CNOnCrusILT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_regression(df,condition1,condition2):\n",
    "    \"\"\" \n",
    "    ---DESCRIPTION---\n",
    "    Perform negative binomial regression between condition1 (assumed to be control) and\n",
    "    condition2 (assumed to be treatment). Uses all batches found in both conditions.\n",
    "    This is not well tested.\n",
    "    ---INPUT---\n",
    "    df:           an NxK dataframe where N rows are the animals and K are the columns, \n",
    "                  which must contain the batch, condition and counts in each brain region\n",
    "    condition1:   a string describing one of the conditions in the dataframe (the control)\n",
    "    condition2:   a string describing one of the conditions in the dataframe (the treatment)\n",
    "    ---OUTPUT--\n",
    "    nb_df:        A dataframe containing the results from the regression on all brain regions in df\n",
    "\n",
    "    Saves to a CSV file called: '../data/{condition1}-{condition2}-counts-nbreg.csv'\n",
    "    \"\"\"\n",
    "    all_predictors = df[['batch','condition']]\n",
    "    all_counts = df.iloc[:,3:]\n",
    "    brain_regions = df.columns[3:]\n",
    "    \n",
    "    condition_mask = (all_predictors['condition']==condition1) | (all_predictors['condition']==condition2)\n",
    "    predictors = all_predictors.loc[condition_mask,:]\n",
    "    design_matrix = dmatrix(\"batch + condition\", predictors,return_type='dataframe')\n",
    "    counts = all_counts.loc[condition_mask,:]\n",
    "    rowsums=np.sum(counts,axis=1)\n",
    "    offsets = np.log(rowsums)\n",
    "    result_list = []\n",
    "    for ii in range(len(brain_regions)):\n",
    "        brain_region=brain_regions[ii]\n",
    "        result_dict = {\n",
    "            'region_idx':ii,\n",
    "            'control':condition1,\n",
    "            'treatment':condition2,\n",
    "            'region':brain_region\n",
    "        }\n",
    "        counts_thisregion = counts[brain_region]\n",
    "        try:\n",
    "            res_nb = sm.GLM(counts_thisregion, design_matrix,family=sm.families.NegativeBinomial(),offset=offsets).fit()\n",
    "            estimate = res_nb.params[-1]\n",
    "            stderr = res_nb.bse[-1]\n",
    "            pvalue = res_nb.pvalues[-1]\n",
    "            zscore = estimate/stderr\n",
    "            status=\"success\"\n",
    "        except:\n",
    "            estimate = np.nan\n",
    "            stderr = np.nan\n",
    "            pvalue = np.nan\n",
    "            zscore = np.nan\n",
    "            status=\"failed\"\n",
    "        result_dict['Estimate'] = estimate\n",
    "        result_dict['Std. Error'] = stderr\n",
    "        result_dict['z value'] = zscore\n",
    "        result_dict['Pr(>|z|)'] = pvalue\n",
    "        result_dict['status'] = status\n",
    "        result_list.append(result_dict)\n",
    "#     print(result_list)\n",
    "    # Now calculate adjusted pvalues\n",
    "    # First sort the whole result_list by p-value, keeping in mind that there can be nans\n",
    "    sorted_result_list = sorted(result_list,\n",
    "            key=lambda x: float('-inf') if np.isnan(x.get('Pr(>|z|)')) else x.get('Pr(>|z|)')) \n",
    "    sorted_p_values = np.array([d.get('Pr(>|z|)') for d in sorted_result_list])\n",
    "    # separate out nans (which are at the beginning of the list due to how we sorted)\n",
    "    p_values_clean = sorted_p_values[~np.isnan(sorted_p_values)]\n",
    "    p_values_nan = sorted_p_values[np.isnan(sorted_p_values)]\n",
    "    # calculate the fdr adjusted p-values\n",
    "    adjusted_p_values_no_nans = bh_correction(p_values_clean)\n",
    "    # add back the nans to the beginning of the list\n",
    "    adj_p_values = np.concatenate([p_values_nan,adjusted_p_values_no_nans])\n",
    "    # add the fdr adjusted p-value into the list of our results\n",
    "    for ii in range(len(sorted_result_list)):\n",
    "        sorted_result_list[ii]['fdr_adj_pval'] = adj_p_values[ii]\n",
    "    # Finally, sort back to original order, the one using brain region index as key\n",
    "    final_result_list = sorted(sorted_result_list,key=lambda x: x.get('region_idx'))\n",
    "    # Make pandas dataframe to make it easier to save to file\n",
    "    nb_df = pd.DataFrame(final_result_list)\n",
    "    nb_df.set_index('region_idx',inplace=True)\n",
    "    # reorder columns\n",
    "    neworder = ['control','treatment','region','Estimate','Std. Error','z value','Pr(>|z|)','fdr_adj_pval','status']\n",
    "    nb_df=nb_df.reindex(columns=neworder)\n",
    "    # Save to csv\n",
    "    savename = f'../data/{condition1}-{condition2}-counts-nbreg.csv'\n",
    "    nb_df.to_csv(savename,index=False)\n",
    "    print(f\"Saved {savename}\")\n",
    "    return nb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n",
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ../data/CNO_control_reversal-CNOnCrusILT-counts-nbreg.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahoag/anaconda3/envs/cfos/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:1227: RuntimeWarning: invalid value encountered in true_divide\n",
      "  endog_mu = self._clean(endog / mu)\n"
     ]
    }
   ],
   "source": [
    "nb_df = nb_regression(df=df,condition1 = 'CNO_control_reversal',condition2 = 'CNOnCrusILT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfos",
   "language": "python",
   "name": "cfos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
