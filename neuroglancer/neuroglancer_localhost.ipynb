{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuroglancer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b94d71bdcb60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneuroglancer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mng\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcloudvolume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neuroglancer'"
     ]
    }
   ],
   "source": [
    "import neuroglancer as ng\n",
    "import cloudvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the neuroglancer client to be one that is hosted locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng.set_static_content_source(url='http://localhost:8080')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the raw data into neuroglancer and generate the link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host the raw-space allen atlas cloudvolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to host this with cloudvolume as was done for the raw data above. Use a different port though, e.g.\n",
    "```python\n",
    "import cloudvolume\n",
    "vol = cloudvolume.Cloudvolume('file:///jukebox/LightSheetTransfer/kelly/neuroglancer/201908_cfos/m61468_observ_rawatlas')\n",
    "vol.viewer(port=1338) # must be a different port than the raw data\n",
    "```\n",
    "Again, make sure to do this outside of this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the atlas\n",
    "Load in a segmentation layer (e.g. the raw-space allen atlas) that is being hosted with cloudvolume using the same viewer object that you already made. If you go back to the neuroglancer window after running this it should be there in a new layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:38514/v/e07435816c454b2abafabe5644b72f02a2dab4d0/\n"
     ]
    }
   ],
   "source": [
    "viewer = ng.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    s.layers['grin'] = ng.ImageLayer(source='precomputed://http://localhost:1337'\n",
    "    )\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_cached_wrappers',\n",
       " '_get_wrapped',\n",
       " '_json_data',\n",
       " '_lock',\n",
       " '_readonly',\n",
       " '_set_wrapped',\n",
       " 'layer',\n",
       " 'name',\n",
       " 'supports_readonly',\n",
       " 'to_json',\n",
       " 'visible']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(viewer.state.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_cached_wrappers',\n",
       " '_get_wrapped',\n",
       " '_json_data',\n",
       " '_lock',\n",
       " '_readonly',\n",
       " '_set_wrapped',\n",
       " 'annotationColor',\n",
       " 'annotationFillOpacity',\n",
       " 'annotation_color',\n",
       " 'annotation_fill_opacity',\n",
       " 'blend',\n",
       " 'crossSectionRenderScale',\n",
       " 'cross_section_render_scale',\n",
       " 'interpolate',\n",
       " 'opacity',\n",
       " 'shader',\n",
       " 'source',\n",
       " 'supports_readonly',\n",
       " 'to_json',\n",
       " 'type']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(viewer.state.layers[0].layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000.0\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    print(s.navigation.zoomFactor)\n",
    "    s.navigation.zoomFactor = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.state.layers[0].layer.shader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '_cached_wrappers', '_get_wrapped', '_json_data', '_lock', '_readonly', '_set_wrapped', 'concurrentDownloads', 'concurrent_downloads', 'crossSectionBackgroundColor', 'cross_section_background_color', 'gpuMemoryLimit', 'gpu_memory_limit', 'interpolate', 'layers', 'layout', 'navigation', 'perspectiveOrientation', 'perspectiveViewBackgroundColor', 'perspectiveZoom', 'perspective_orientation', 'perspective_view_background_color', 'perspective_zoom', 'position', 'selectedLayer', 'selected_layer', 'showAxisLines', 'showDefaultAnnotations', 'showScaleBar', 'showSlices', 'show_axis_lines', 'show_default_annotations', 'show_scale_bar', 'show_slices', 'statistics', 'supports_readonly', 'systemMemoryLimit', 'system_memory_limit', 'to_json', 'voxel_coordinates', 'voxel_size']\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    print(dir(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers[0].layer.shader = \"\"\"void main() { emitGrayscale(toNormalized(getDataValue())*25.0);}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
