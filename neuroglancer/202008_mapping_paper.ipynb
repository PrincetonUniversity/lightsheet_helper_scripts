{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "This notebook covers how to start the Neuroglancer viewer, load in some data, and customize the Neuroglancer window all in Python. It assumes you already have a local copy of the Neuroglancer layer directories for the raw data, raw atlas and raw cells. These are on bucket here:\n",
    "\n",
    "\n",
    "- raw data layer: /jukebox/LightSheetData/lightserv_testing/neuroglancer/201904_ymaze_cfos/rawdata_an21/\n",
    "- raw atlas layer: /jukebox/LightSheetData/lightserv_testing/neuroglancer/201904_ymaze_cfos/rawatlas_an21/\n",
    "- raw cells layer: /jukebox/LightSheetData/lightserv_testing/neuroglancer/201904_ymaze_cfos/rawcells_an21_dilated/\n",
    "\n",
    "All together than are about 8 GB so copy them to your local machine if possible. It will speed up the load into Neuroglancer enormously because you will not need to use the VPN. \n",
    "\n",
    "## A quick note about Neuroglancer\n",
    "Neuroglancer loads in datasets in \"layers\". A layer can be of type \"image\" (like the raw data layer above) or type \"segmentation\" (like an atlas layer or cell layer). The naming is a little confusing because both layer types refer to volumes (3-d arrays). In Neuroglancer, you can overlay multiple layers or view them side-by-side, turn them on and off, and lots more. See the tutorial at [https://brainmaps.princeton.edu/2020/05/getting-started-with-neuroglancer/](https://brainmaps.princeton.edu/2020/05/getting-started-with-neuroglancer/) to learn more about what you can do with Neuroglancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "In order to run the code in this notebook, you will need an anaconda environment with python3 and containing some additional libraries. This environment \"ng_ymaze\" can be set up in the following way:\n",
    "In terminal:\n",
    "- conda create -n ng_ymaze python=3.7.4 -y\n",
    "- conda activate ng_ymaze # (or source activate ng_mriatlas, depending on which version of conda you have)\n",
    "- git clone https://github.com/austinhoag/cloud-volume # this fork has the fix for windows paths while we wait for the official seung-lab cloudvolume repo to incorporate the changes \n",
    "- cd cloud-volume\n",
    "- pip install -e . \n",
    "- **pip install neuroglancer==1.1.6** <br>\n",
    "- pip install --user ipykernel # to enable using this conda environment as a jupyter kernel\n",
    "- python -m ipykernel install --user --name=ng_ymaze\n",
    "\n",
    "At this point, make sure to select this conda environment as the kernel when running this notebook (you might have to restart the notebook server, i.e. re-run jupyter notebook from the terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host your layers on your local computer's network\n",
    "This is a lot easier than it sounds. Open up a new terminal window on your computer and enter your ng_ymaze conda environment:\n",
    "- conda activate ng_ymaze\n",
    "\n",
    "Now enter a python interactive shell:\n",
    "- python\n",
    "\n",
    "Now execute the following lines in the python session:\n",
    "```python\n",
    "###WINDOW 1###\n",
    "#in a new ipython window:\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"07142020_tp_hsv20hr_6\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1350\n",
    "#layer_dir = \"/jukebox/scratch/zmd/save/contra_ipsi_projection_studies_20191125/%s/647\" % brainname\n",
    "src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_HSV-H129/natneuroreviews_tompisano_HSV-H129_20hr-006/imaging_request_1/viz/\"\n",
    "layer_dir = os.path.join(src, brainname, \"647\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port)\n",
    "\n",
    "#or for CTB\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"PRV_36hr-015\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1354\n",
    "src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_PRV/natneuroreviews_tompisano_PRV_36hr-015/imaging_request_1/viz\"\n",
    "layer_dir = os.path.join(src, brainname, \"642\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port)\n",
    "\n",
    "#or for PRV\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"20200701_14_15_35_20180205_jg_b6f_04\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1350\n",
    "layer_dir = \"/jukebox/scratch/zmd/save/contra_ipsi_projection_studies_20191125/%s/647\" % brainname\n",
    "#src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_HSV-H129/natneuroreviews_tompisano_HSV-H129_20hr-006/imaging_request_1/viz/\"\n",
    "#layer_dir = os.path.join(src, brainname, \"647\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port)\n",
    "```\n",
    "\n",
    "This should cause your session to hang -- that is expected. \n",
    "\n",
    "Now open up another terminal window and do the same thing but for the raw atlas, e.g.:\n",
    "- conda activate ng_ymaze\n",
    "- python \n",
    "\n",
    "Then, in python:\n",
    "```python\n",
    "###WINDOW 2###\n",
    "#to add another layer (aka the atlas), in a new ipython window:\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"07142020_tp_hsv20hr_6\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1350\n",
    "#layer_dir = \"/jukebox/scratch/zmd/save/contra_ipsi_projection_studies_20191125/%s/atlas\" % brainname\n",
    "src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_HSV-H129/natneuroreviews_tompisano_HSV-H129_20hr-006/imaging_request_1/viz/\"\n",
    "layer_dir = os.path.join(src, brainname, \"atlas\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port+1) #make sure this port is different from the first    \n",
    "\n",
    "#or for CTB/PRV\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"PRV_36hr-015\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1354\n",
    "src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_PRV/natneuroreviews_tompisano_PRV_36hr-015/imaging_request_1/viz\"\n",
    "layer_dir = os.path.join(src, brainname, \"atlas\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port+1) #make sure this port is different from the first    \n",
    "\n",
    "\n",
    "#or for PRV\n",
    "from cloudvolume import CloudVolume\n",
    "import os\n",
    "brainname = \"20200701_14_15_35_20180205_jg_b6f_04\" #\"20150804_tp_bl6_ts04\"\n",
    "port=1350\n",
    "layer_dir = \"/jukebox/scratch/zmd/save/contra_ipsi_projection_studies_20191125/%s/atlas\" % brainname\n",
    "#src = \"/jukebox/LightSheetData/lightserv/jverpeut/natneuroreviews_tompisano_HSV-H129/natneuroreviews_tompisano_HSV-H129_20hr-006/imaging_request_1/viz/\"\n",
    "#layer_dir = os.path.join(src, brainname, \"647\")\n",
    "vol = CloudVolume(f\"file://{layer_dir}\")\n",
    "vol.viewer(port=port+1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your layers into Neuroglancer and view them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer \n",
    "neuroglancer.set_static_content_source(url=\"https://nglancer.pni.princeton.edu\")\n",
    "brainname = \"20200701_14_15_35_20180205_jg_b6f_04\"#\"20150804_tp_bl6_ts04\" #\"07142020_tp_hsv20hr_6\"\n",
    "port=1350\n",
    "viewer = neuroglancer.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:46153/v/27dfba7dc95c1944e0b5639e150b7ad771decec3/\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers[\"%s\" % brainname] = neuroglancer.ImageLayer(source=\"precomputed://http://localhost:%s\" % port\n",
    "    )\n",
    "print(viewer)\n",
    "#this should add the above volume to the neuroglancer window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:46153/v/27dfba7dc95c1944e0b5639e150b7ad771decec3/\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers[\"%s_atlas\" % brainname] = neuroglancer.SegmentationLayer(source=\"precomputed://http://localhost:%s\" % int(port+1)\n",
    "    )\n",
    "print(viewer)\n",
    "#this should add the atlas volume to the neuroglancer window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '/home/wanglab/Desktop/0000000.png')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# old screenshot way\n",
    "ss = neuroglancer.ScreenshotSaver(viewer, '/home/wanglab/Desktop')\n",
    "ss.capture() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8489ff59ff54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvoxel_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2927\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m723\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#the xy coords here are from the neuroglancer window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuroglancer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScreenshotSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%06d.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#ebdriver.driver.save_screenshot(os.path.join(svdst, \"%06d.png\" % i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ng36/lib/python3.6/site-packages/neuroglancer/screenshot.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreenshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mincrement_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ng36/lib/python3.6/site-packages/neuroglancer/viewer_base.py\u001b[0m in \u001b[0;36mscreenshot\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_screenshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ng36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ng36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "with viewer.config_state.txn() as s:\n",
    "    s.show_ui_controls = False\n",
    "    s.show_panel_borders = False\n",
    "svdst = \"/home/wanglab/Desktop/%s/prv_coronal_wo_overlay \"% brainname\n",
    "#make sure these directories exist\n",
    "if not os.path.exists(os.path.dirname(svdst)): os.mkdir(os.path.dirname(svdst)) #brain directory\n",
    "if not os.path.exists(svdst): os.mkdir(svdst) #structure directory\n",
    "for i in range(4000,5000,50):\n",
    "    if i%10==0: print(i)\n",
    "    with viewer.txn() as s:\n",
    "        s.voxel_coordinates = [2927,i,723] #the xy coords here are from the neuroglancer window\n",
    "    s = neuroglancer.ScreenshotSaver(viewer, os.path.join(svdst, \"%06d.png\" % i))\n",
    "    ss.capture()\n",
    "    #ebdriver.driver.save_screenshot(os.path.join(svdst, \"%06d.png\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webdriver which should open a new window\n",
    "import os, time\n",
    "from neuroglancer import webdriver\n",
    "webdriver = webdriver.Webdriver(viewer, headless=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.config_state.txn() as s:\n",
    "    s.show_ui_controls = False\n",
    "    s.show_panel_borders = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svdst = \"/home/wanglab/Desktop/%s/prv_coronal_wo_overlay \"% brainname\n",
    "#make sure these directories exist\n",
    "if not os.path.exists(os.path.dirname(svdst)): os.mkdir(os.path.dirname(svdst)) #brain directory\n",
    "if not os.path.exists(svdst): os.mkdir(svdst) #structure directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000,3000,50):\n",
    "    with viewer.txn() as s:\n",
    "        s.voxel_coordinates = [2927,i,723] #the xy coords here are from the neuroglancer window\n",
    "    time.sleep(30)\n",
    "    webdriver.driver.save_screenshot(os.path.join(svdst, \"%06d.png\" % i))\n",
    "    #s = neuroglancer.ScreenshotSaver(viewer, svdst)\n",
    "    #ss.capture(i)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off atlas layer\n",
    "with webdriver.viewer.txn() as s:\n",
    "    annotlayer = s.layers[\"%s_atlas\" % brainname]\n",
    "    annotlayer.visible=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get more screenshots\n",
    "svdst = \"/home/wanglab/Desktop/%s/dcn_wo_overlay \"% brainname\n",
    "#make sure these directories exist\n",
    "if not os.path.exists(os.path.dirname(svdst)): os.mkdir(os.path.dirname(svdst)) #brain directory\n",
    "if not os.path.exists(svdst): os.mkdir(svdst) #structure directory\n",
    "\n",
    "for i in range(5166,6056,20):\n",
    "    if i%10==0: print(i)\n",
    "    with viewer.txn() as s:\n",
    "        s.voxel_coordinates = [2788,i,749] #the xy coords here are from the neuroglancer window\n",
    "        #(where the L center scale is located)\n",
    "    #optionally limit window size\n",
    "#    with viewer.config_state.txn() as s:\n",
    "#        s.viewer_size = [1000,1000]\n",
    "    time.sleep(40)\n",
    "    webdriver.driver.save_screenshot(os.path.join(svdst, \"%06d.png\" % i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after, return controls to neuroglancer browser\n",
    "with viewer.config_state.txn() as s: \n",
    "    s.show_ui_controls = True \n",
    "    s.show_panel_borders = True "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ng36",
   "language": "python",
   "name": "ng36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
