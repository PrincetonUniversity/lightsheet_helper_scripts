{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jess_cfos_for_gallery-webdriver\n",
    "I used this notebook to make the lightserv gallery gif of Thalamic expression in Jess' c-Fos an21 subject.\n",
    "\n",
    "This notebook saves a bunch of pngs which I then convert to gif using a python script, e.g.:\n",
    "```python\n",
    "from PIL import Image\n",
    "import glob, os\n",
    " \n",
    "ss_dir = '/home/ahoag/ngdemo/screenshots/cfos_an21'\n",
    "savename = os.path.join(ss_dir,'cfos_an21.gif')\n",
    "if __name__ == '__main__':\n",
    "\t# Create the frames\n",
    "\tpngs = sorted(glob.glob(ss_dir+'/*png'))\n",
    "\tprint(pngs)\n",
    "\tframes = [Image.open(png) for png in pngs]\n",
    "\t\n",
    "\t# Save into a GIF file that loops forever\n",
    "\tframes[0].save(savename, format='GIF', append_images=frames[1:], save_all=True, duration=200, loop=0)\n",
    "```\n",
    "I was having trouble getting the segment properties to be displayed in the png screenshots - I opened an issue on the google github for this: https://github.com/google/neuroglancer/issues/233. It can be achieved using the selenium webdriver as done below. In order to get the webdriver to work I had to pip install selenium (not included with neuroglancer pip), then I had to download the chromedriver binary from here: https://chromedriver.chromium.org/downloads since I was using google chrome as my browser. Make sure to put the \"chromedriver\" executable in your shell path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5c3bfa2ae468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuroglancer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwebd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import neuroglancer as ng\n",
    "from neuroglancer import webdriver as webd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the neuroglancer client to be one that is hosted locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use localhost for static files\n",
    "# ng.set_static_content_source(url='http://localhost:8080')\n",
    "ng.set_static_content_source(url='https://nglancer.pni.princeton.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/\n"
     ]
    }
   ],
   "source": [
    "# Start a web viewer and load in my three layers, which are hosted on my local machine.\n",
    "# Note that I used raw-space annotation layer for the cells, but I put a high \"limit\" on it (~500000)\n",
    "# So that the number of cells displayed was low -- with the native sampling the cells are too dense\n",
    "# to see anything else\n",
    "viewer = ng.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    s.layers['rawdata_an21'] = ng.ImageLayer(source='precomputed://gs://wanglab-pma/cfos_example/rawdata_an21'\n",
    "    )\n",
    "    s.layers['rawatlas_an21'] = ng.SegmentationLayer(source='precomputed://gs://wanglab-pma/cfos_example/rawatlas_an21'\n",
    "    )\n",
    "#     s.layers['rawcells_an21'] = ng.AnnotationLayer(source='precomputed://http://localhost:8086'\n",
    "#     )\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegmentationLayer({\"type\": \"segmentation\", \"source\": \"precomputed://gs://wanglab-pma/cfos_example/rawatlas_an21\", \"name\": \"rawatlas_an21\"})\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    atlas_layer =s.layers[1]\n",
    "#     print(dir(atlas_layer.layer))\n",
    "    print(atlas_layer.layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the webdriver which should open a new window\n",
    "webdriver = webd.Webdriver(viewer, headless=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8080/sockjs-node/info?t=1611068474367 - Failed to load resource: net::ERR_CONNECTION_REFUSED\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/main.bundle.js 36877:8 \"[WDS] Disconnected!\"\n",
      "http://127.0.0.1:42073/favicon.ico - Failed to load resource: the server responded with a status of 404 (Not Found)\n",
      "http://127.0.0.1:8080/sockjs-node/info?t=1611068475458 - Failed to load resource: net::ERR_CONNECTION_REFUSED\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 26235 [WDS] Disconnected!\n",
      "https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2Fmesh_mip_0_err_40%2Finfo?alt=media - Failed to load resource: the server responded with a status of 404 ()\n",
      "http://127.0.0.1:8080/sockjs-node/info?t=1611068477538 - Failed to load resource: net::ERR_CONNECTION_REFUSED\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,2: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_128-192?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,8: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_512-576?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,3: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_192-256?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,7: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_448-512?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,4: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_256-320?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,6: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_384-448?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:42073/v/769fe0b1fbb89421d8aa77e0333155804d95bd0e/chunk_worker.bundle.js 28732 Error retrieving chunk [object Object]:0,0,5: HttpError: Fetching \"https://www.googleapis.com/storage/v1/b/wanglab-pma/o/cfos_example%2Frawatlas_an21%2F80000_80000_10000%2F0-128_0-128_320-384?alt=media\" resulted in HTTP error 404.\n",
      "http://127.0.0.1:8080/sockjs-node/info?t=1611068481692 - Failed to load resource: net::ERR_CONNECTION_REFUSED\n"
     ]
    }
   ],
   "source": [
    "webdriver.driver.set_window_size(1700,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where I take the sequence of screenshots \n",
    "\n",
    "# Set up the initial frame\n",
    "with webdriver.viewer.txn() as s:\n",
    "    s.layout = 'yz-3d'\n",
    "    s.position = [1710,1276,331]\n",
    "    \n",
    "    s.cross_section_orientation = [0.7071067690849304, 0, 0, 0.7071067690849304]\n",
    "    s.cross_section_scale = 5.5\n",
    "    s.projection_scale = 3900\n",
    "    s.projection_orientation = [0.65080833, 0.17286249, 0.20033664, 0.7116406 ]\n",
    "    seglayer = s.layers['rawatlas_an21']\n",
    "    seglayer.segments = [549, 262, 741, 149, 629, 599, 1113, 733]\n",
    "    seglayer.segment_query = \"549, 262, 741, 149, 629, 599, 1113, 733\"\n",
    "    annotlayer = s.layers['rawcells_an21']\n",
    "    annotlayer.visible=False\n",
    "    annotlayer.shader = \"\\nvoid main() {\\n  setColor(vec4(defaultColor(), 0.5));\\n}\"\n",
    "    s.selected_layer.layer = 'rawatlas_an21' \n",
    "    s.selected_layer.visible = True\n",
    "    s.selected_layer.size = 715\n",
    "    s.layers['rawatlas_an21'].tab = \"segments\"\n",
    "    s.show_axis_lines=False\n",
    "\n",
    "savedst = '/home/ahoag/ngdemo/screenshots/cfos_an21'\n",
    "# Do a sweep through sagittal sections\n",
    "ss_ii = 0\n",
    "for i in range(400,1600,50):\n",
    "    with webdriver.viewer.txn() as s:\n",
    "        s.position = [i,1265,359] #the xy coords here are from the neuroglancer window\n",
    "    webdriver.driver.save_screenshot(os.path.join(savedst,f'{ss_ii}.png'.zfill(6)))\n",
    "    ss_ii += 1\n",
    "# Turn on cell layer and sweep back\n",
    "with webdriver.viewer.txn() as s:\n",
    "    annotlayer = s.layers['rawcells_an21']\n",
    "    annotlayer.visible=True\n",
    "for i in range(1550,350,-50):\n",
    "    with webdriver.viewer.txn() as s:\n",
    "        s.position = [i,1265,359] #the xy coords here are from the neuroglancer window\n",
    "    webdriver.driver.save_screenshot(os.path.join(savedst,f'{ss_ii}.png'.zfill(6)))\n",
    "    ss_ii += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ng",
   "language": "python",
   "name": "ng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
