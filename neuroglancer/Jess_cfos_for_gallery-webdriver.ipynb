{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jess_cfos_for_gallery-webdriver\n",
    "I used this notebook to make the lightserv gallery gif of Thalamic expression in Jess' c-Fos an21 subject.\n",
    "\n",
    "This notebook saves a bunch of pngs which I then convert to gif using a python script, e.g.:\n",
    "```python\n",
    "from PIL import Image\n",
    "import glob, os\n",
    " \n",
    "ss_dir = '/home/ahoag/ngdemo/screenshots/cfos_an21'\n",
    "savename = os.path.join(ss_dir,'cfos_an21.gif')\n",
    "if __name__ == '__main__':\n",
    "\t# Create the frames\n",
    "\tpngs = sorted(glob.glob(ss_dir+'/*png'))\n",
    "\tprint(pngs)\n",
    "\tframes = [Image.open(png) for png in pngs]\n",
    "\t\n",
    "\t# Save into a GIF file that loops forever\n",
    "\tframes[0].save(savename, format='GIF', append_images=frames[1:], save_all=True, duration=200, loop=0)\n",
    "```\n",
    "I was having trouble getting the segment properties to be displayed in the png screenshots - I opened an issue on the google github for this: https://github.com/google/neuroglancer/issues/233. It can be achieved using the selenium webdriver as done below. In order to get the webdriver to work I had to pip install selenium (not included with neuroglancer pip), then I had to download the chromedriver binary from here: https://chromedriver.chromium.org/downloads since I was using google chrome as my browser. Make sure to put the \"chromedriver\" executable in your shell path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuroglancer as ng\n",
    "from neuroglancer import webdriver\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the neuroglancer client to be one that is hosted locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use localhost for static files\n",
    "ng.set_static_content_source(url='http://localhost:8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:34237/v/cef0fb86dee23295ebcc2f897b6dd05ff9bad33f/\n"
     ]
    }
   ],
   "source": [
    "# Start a web viewer and load in my three layers, which are hosted on my local machine.\n",
    "# Note that I used raw-space annotation layer for the cells, but I put a high \"limit\" on it (~500000)\n",
    "# So that the number of cells displayed was low -- with the native sampling the cells are too dense\n",
    "# to see anything else\n",
    "viewer = ng.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    s.layers['rawdata_an21'] = ng.ImageLayer(source='precomputed://http://localhost:1337'\n",
    "    )\n",
    "    s.layers['rawatlas_an21'] = ng.SegmentationLayer(source='precomputed://http://localhost:1338'\n",
    "    )\n",
    "    s.layers['rawcells_an21'] = ng.AnnotationLayer(source='precomputed://http://localhost:8086'\n",
    "    )\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:34237/v/cda13063be101eec422dac8a73814375e01fddd6/\n"
     ]
    }
   ],
   "source": [
    "viewer = ng.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    s.layers['rawatlas_an21'] = ng.SegmentationLayer(source='precomputed://http://localhost:1338'\n",
    "    )\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'neuroglancer' has no attribute 'webdriver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba56b6c819cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start the webdriver which should open a new window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwebdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWebdriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'neuroglancer' has no attribute 'webdriver'"
     ]
    }
   ],
   "source": [
    "# Start the webdriver which should open a new window\n",
    "webdriver = webdriver.Webdriver(viewer, headless=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webdriver.driver.set_window_size(1700,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where I take the sequence of screenshots \n",
    "\n",
    "# Set up the initial frame\n",
    "with webdriver.viewer.txn() as s:\n",
    "    s.layout = 'yz-3d'\n",
    "    s.position = [1710,1276,331]\n",
    "    \n",
    "    s.cross_section_orientation = [0.7071067690849304, 0, 0, 0.7071067690849304]\n",
    "    s.cross_section_scale = 5.5\n",
    "    s.projection_scale = 3900\n",
    "    s.projection_orientation = [0.65080833, 0.17286249, 0.20033664, 0.7116406 ]\n",
    "    seglayer = s.layers['rawatlas_an21']\n",
    "    seglayer.segments = [549, 262, 741, 149, 629, 599, 1113, 733]\n",
    "    seglayer.segment_query = \"549, 262, 741, 149, 629, 599, 1113, 733\"\n",
    "    annotlayer = s.layers['rawcells_an21']\n",
    "    annotlayer.visible=False\n",
    "    annotlayer.shader = \"\\nvoid main() {\\n  setColor(vec4(defaultColor(), 0.5));\\n}\"\n",
    "    s.selected_layer.layer = 'rawatlas_an21' \n",
    "    s.selected_layer.visible = True\n",
    "    s.selected_layer.size = 715\n",
    "    s.layers['rawatlas_an21'].tab = \"segments\"\n",
    "    s.show_axis_lines=False\n",
    "\n",
    "savedst = '/home/ahoag/ngdemo/screenshots/cfos_an21'\n",
    "# Do a sweep through sagittal sections\n",
    "ss_ii = 0\n",
    "for i in range(400,1600,50):\n",
    "    with webdriver.viewer.txn() as s:\n",
    "        s.position = [i,1265,359] #the xy coords here are from the neuroglancer window\n",
    "    webdriver.driver.save_screenshot(os.path.join(savedst,f'{ss_ii}.png'.zfill(6)))\n",
    "    ss_ii += 1\n",
    "# Turn on cell layer and sweep back\n",
    "with webdriver.viewer.txn() as s:\n",
    "    annotlayer = s.layers['rawcells_an21']\n",
    "    annotlayer.visible=True\n",
    "for i in range(1550,350,-50):\n",
    "    with webdriver.viewer.txn() as s:\n",
    "        s.position = [i,1265,359] #the xy coords here are from the neuroglancer window\n",
    "    webdriver.driver.save_screenshot(os.path.join(savedst,f'{ss_ii}.png'.zfill(6)))\n",
    "    ss_ii += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ng",
   "language": "python",
   "name": "ng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
