{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register_raw_brains (python 3.6+)\n",
    "The purpose of this notebook is to align multiple brains in their raw space by shifting them so that the center of mass of an atlas region is aligned. The procedure for this is as follows:\n",
    "1. Each raw space brain gets a raw space atlas by back-transforming the atlas using the registration transformation parameters. \n",
    "2. One brain is chosen as the reference brain\n",
    "3. For each brain (including reference brain), calculate the center of mass of a region on which you want to align the brains\n",
    "4. Calculate the offset (dx,dy,dz) between the center of mass of this region between each brain and the reference brain.\n",
    "5. Apply the offset to each of the brains to align them to the reference brain. \n",
    "\n",
    "We will use the 201908_cfos dataset as a test of this concept. Step 1 has already been run for this. Step 3 proof of concept is shown in [Center_of_mass_atlas.ipynb](Center_of_mass_atlas.ipynb). Step 5 proof of concept is shown in [shift_array.ipynb](shift_array.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudvolume\n",
    "import neuroglancer\n",
    "import numpy as np\n",
    "import os,glob\n",
    "import time\n",
    "import tifffile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '/jukebox/LightSheetTransfer/kelly/201908_cfos' # contains subdirectories with the raw data for each brain\n",
    "atlas_dir = '/jukebox/scratch/kellyms' # contains subdirectories with the raw-space annotation atlases for each brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning 2 brains \n",
    "Let's start simple and align two \"observ\" brains based on a given brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_observ_dirs(channel='647'):\n",
    "    \"\"\" Find subdirectories of the root directory that contain\n",
    "    \"observ\" and the channel name in them\n",
    "    \"\"\"\n",
    "    assert type(channel) == str\n",
    "    observ_dirs = glob.glob(raw_dir + '/*observ*%s*' % channel)\n",
    "    return observ_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/jukebox/LightSheetTransfer/kelly/201908_cfos/190820_m61468_observ_20190628_1d3x_647_008na_1hfds_z5um_250msec_14-50-40',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190821_f61465_observ_20190626_1d3x_647_008na_1hfds_z5um_250msec_12-20-20',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190822_f62159_observ_20190625_1d3x_647_008na_1hfds_z5um_250msec_13-13-43',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190821_f62196_observ_20190626_1d3x_647_008na_1hfds_z5um_250msec_10-50-16',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190822_m61467_observ_20190702_1d3x_647_008na_1hfds_z5um_250msec_18-56-46',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190822_m62181_observ_20190702_1d3x_647_008na_1hfds_z5um_250msec_16-02-35',\n",
       " '/jukebox/LightSheetTransfer/kelly/201908_cfos/190822_f61494_observ_20190625_1d3x_647_008na_1hfds_z5um_250msec_17-24-19']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_observ_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick first two as an example\n",
    "all_observ_dirs = find_observ_dirs()\n",
    "test_observ_dirs = all_observ_dirs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m61468_observ', 'f61465_observ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The string we need to find the raw space atlas is the \"m61468_observ\" part, so let's strip that out\n",
    "test_animal_ids = ['_'.join(x.split('/')[-1].split('_')[1:3]) for x in test_observ_dirs]\n",
    "test_animal_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab raw atlas files and put them in a list of lists\n",
    "test_raw_atlas_files = []\n",
    "for animal_id in test_animal_ids:\n",
    "    subdirs = glob.glob(atlas_dir + f'/{animal_id}*')\n",
    "    assert len(subdirs) == 1\n",
    "    subdir = subdirs[0]\n",
    "    raw_atlas_files = sorted(glob.glob(subdir + '/annotations_as_single_tifs/*tif'))\n",
    "    test_raw_atlas_files.append(raw_atlas_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 24116it [01:43, 325.36it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# Read in raw atlases into numpy arrays\n",
    "vol_m61468_atlas = cloudvolume.CloudVolume('file:///home/ahoag/ngdemo/demo_bucket/201908_cfos/m61468_observ_rawatlas')\n",
    "data_m61468_atlas = np.transpose(vol_m61468_atlas[:][...,0],(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 22758it [01:46, 156.62it/s]                           \n"
     ]
    }
   ],
   "source": [
    "vol_f61465_atlas = cloudvolume.CloudVolume('file:///home/ahoag/ngdemo/demo_bucket/201908_cfos/f61465_observ_rawatlas')\n",
    "data_f61465_atlas = np.transpose(vol_f61465_atlas[:][...,0],(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1342, 2560, 2160)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m61468_atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make sure they share the same label ids \n",
    "segments_1 = np.unique(data_m61468_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_2 = np.unique(data_f61465_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(segments_1,segments_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the IDs in the two raw-space atlases are the same which is reassuring. It means that we can reliably test the align-by-region procedure described above.\n",
    "\n",
    "Let's pick a region of interest, find its ID, then try to align based on the center of mass of that ID.\n",
    "\n",
    "Let's choose the parabrachial nucleus (ID=867) since that is one where Kelly was looking for her signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 867 in segments_1\n",
    "assert 867 in segments_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate centers of mass for Parabrachial nucleus (ID=867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_center_of_mass3D(a,label):\n",
    "    \"\"\"\n",
    "    ---PURPOSE---\n",
    "    Calculate center of mass of a label (aka \"id\" or \"segment\")\n",
    "    in a 3D numpy array. \n",
    "    ---INPUT---\n",
    "    a        3D numpy array\n",
    "    label    An integer id that is in the array\n",
    "    ---OUTPUT--\n",
    "    z_avg    Average z coordinate of the label in the array\n",
    "    y_avg    Average y coordinate of the label in the array\n",
    "    x_avg    Average x coordinate of the label in the array\n",
    "             It returns them in this order (z,y,x) to conform with output of scipy's center of mass fn\n",
    "    \"\"\"\n",
    "    z_indices,y_indices,x_indices = np.where(a==label)\n",
    "    z_avg,y_avg,x_avg = np.mean((z_indices,y_indices,x_indices),axis=1)\n",
    "    return np.array([z_avg,y_avg,x_avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#z_avg, y_avg, x_avg\n",
      "[ 617.87333611 1824.06316462 1089.66179349]\n",
      "[ 595.18092685 1810.88187478 1093.82468293]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'f2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-2409957c2269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_of_mass_867_brain2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Took {f2-f1} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f2' is not defined"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "center_of_mass_867_brain1 = calc_center_of_mass3D(a=data_m61468_atlas,label=867)\n",
    "center_of_mass_867_brain2 = calc_center_of_mass3D(a=data_f61465_atlas,label=867)\n",
    "print(\"#z_avg, y_avg, x_avg\")\n",
    "print(center_of_mass_867_brain1)\n",
    "print(center_of_mass_867_brain2)\n",
    "t2 = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 37.94324218800011 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Took {t2-t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose **brain 1 to be the reference brain** and shift brain 2 to align with brain 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting brain 2 to align with brain 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.69240925, 13.18128984, -4.16288944])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First calculate the offsets\n",
    "offset_zyx_float = center_of_mass_867_brain1-center_of_mass_867_brain2\n",
    "offset_zyx_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 13, -4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can only shift by integers, so will need to round these offsets\n",
    "offset_zyx = [int(round(i)) for i in offset_zyx_float]\n",
    "offset_zyx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how much I need to shift Brain 2 so that it is aligned with Brain 1. \n",
    "\n",
    "Let's test this by making a copy of atlas 2 and then shifting it by this much and then recalculating center of mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 5.439611916999638 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "z_offset,y_offset,x_offset = offset_zyx\n",
    "data_f61465_atlas_aligned2_brain1 = np.roll(data_f61465_atlas,shift=(x_offset,y_offset,z_offset),axis=(2,1,0))\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Took {t2-t1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#z_avg, y_avg, x_avg\n",
      "Brain 1: [ 617.87333611 1824.06316462 1089.66179349]\n",
      "Brain 2: [ 595.18092685 1810.88187478 1093.82468293]\n",
      "Brain 2, shifted: [ 618.18092685 1823.88187478 1089.82468293]\n"
     ]
    }
   ],
   "source": [
    "# Recalculate center of mass\n",
    "center_of_mass_867_brain2_shifted = calc_center_of_mass3D(a=shifted_raw_atlas_data_2,label=867)\n",
    "print(\"#z_avg, y_avg, x_avg\")\n",
    "print(\"Brain 1:\", center_of_mass_867_brain1)\n",
    "print(\"Brain 2:\",center_of_mass_867_brain2)\n",
    "print(\"Brain 2, shifted:\",center_of_mass_867_brain2_shifted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so it got to within a half pixel in each dimension of Brain 1.\n",
    "\n",
    "Now let's align the actual raw data volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 24172it [02:01, 166.66it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# First need to load in both brains\n",
    "# Brain 1\n",
    "vol_m61468 = cloudvolume.CloudVolume('file:///home/ahoag/ngdemo/demo_bucket/201908_cfos/190820_m61468_observ')\n",
    "data_m61468 = np.transpose(vol_m61468[:][...,0],(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 22766it [01:57, 165.35it/s]                           \n"
     ]
    }
   ],
   "source": [
    "# Brain 2\n",
    "vol_f61465 = cloudvolume.CloudVolume('file:///home/ahoag/ngdemo/demo_bucket/201908_cfos/190821_f61465_observ/')\n",
    "data_f61465 = np.transpose(vol_f61465[:][...,0],(2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1266, 2560, 2160)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f61465.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 2560, 2160)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f61465_atlas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343, 2560, 2160)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m61468.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1342, 2560, 2160)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m61468_atlas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First lets view a single brain in Neuroglancer along with its raw data atlas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:40244/v/e3d253a1226f664a47aafc9d400fc2489c281184/\n"
     ]
    }
   ],
   "source": [
    "# So we can compare once we hvae applied the offset \n",
    "viewer = neuroglancer.Viewer()\n",
    "# This volume handle can be used to notify the viewer that the data has changed.\n",
    "volume_m61468 = neuroglancer.LocalVolume(\n",
    "        data=data_m61468, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='image',\n",
    "         )\n",
    "volume_m61468_atlas = neuroglancer.LocalVolume(\n",
    "        data=data_m61468_atlas, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='segmentation',\n",
    "         )\n",
    "with viewer.txn() as s:\n",
    "#     s.layers['m61468'] = neuroglancer.ImageLayer(\n",
    "#         source=volume_m61468,\n",
    "#         shader=\"\"\"\n",
    "#         void main() {\n",
    "#         float v = toNormalized(getDataValue(0)) * 20.0;\n",
    "#         emitRGBA(vec4(0.0, v, 0.0, v));\n",
    "#         }\n",
    "#         \"\"\",\n",
    "#     )\n",
    "    s.layers['atlas_m61468'] = neuroglancer.SegmentationLayer(source=volume_m61468_atlas\n",
    "    )\n",
    "\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's add the two layers for Brain 2, unshifted first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_f61465 = neuroglancer.LocalVolume(\n",
    "        data=data_f61465, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='image',\n",
    "         )\n",
    "volume_f61465_atlas = neuroglancer.LocalVolume(\n",
    "        data=data_f61465_atlas, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='segmentation',\n",
    "         )\n",
    "with viewer.txn() as s:\n",
    "#     s.layers['f61465'] = neuroglancer.ImageLayer(\n",
    "#         source=volume_f61465,\n",
    "#         shader=\"\"\"\n",
    "#         void main() {\n",
    "#         float v = toNormalized(getDataValue(0)) * 20.0;\n",
    "#         emitRGBA(vec4(v, 0.0, 0.0, v));\n",
    "#         }\n",
    "#         \"\"\",\n",
    "#     )\n",
    "    s.layers['atlas_f61465'] = neuroglancer.SegmentationLayer(source=volume_f61465_atlas\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That really allows you to see that there is rotation or shift or both. Let's now overlay instead the shifted atlas and raw data from brain 2.\n",
    "## Viewing brain 1 and brain 2 shifted to align in the parabrachial nucleus (ID=867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 6.800327957000263 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "data_f61465_aligned2_brain1 = np.roll(data_f61465,shift=(x_offset,y_offset,z_offset),axis=(2,1,0))\n",
    "t2 = time.perf_counter()\n",
    "print(f\"Took {t2-t1} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_f61465_shifted = neuroglancer.LocalVolume(\n",
    "        data=data_f61465_aligned2_brain1, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='image',\n",
    "         )\n",
    "volume_f61465_atlas_shifted = neuroglancer.LocalVolume(\n",
    "        data=data_f61465_atlas_aligned2_brain1, # need it in z,y,x order, strangely\n",
    "        voxel_size=[5000,5000,5000],\n",
    "        voxel_offset = [0, 0, 0], # x,y,z in nm not voxels\n",
    "        volume_type='segmentation',\n",
    "         )\n",
    "with viewer.txn() as s:\n",
    "    s.layers['f61465'] = neuroglancer.ImageLayer(\n",
    "        source=volume_f61465_shifted,\n",
    "        shader=\"\"\"\n",
    "        void main() {\n",
    "        float v = toNormalized(getDataValue(0)) * 20.0;\n",
    "        emitRGBA(vec4(v, 0.0, 0.0, v));\n",
    "        }\n",
    "        \"\"\",\n",
    "    )\n",
    "    s.layers['atlas_f61465'] = neuroglancer.SegmentationLayer(source=volume_f61465_atlas_shifted\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 713, in _handle_events\n",
      "    self._handle_write()\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 1063, in _handle_write\n",
      "    self._write_buffer.advance(num_bytes)\n",
      "  File \"/home/ahoag/anaconda3/envs/lightserv/lib/python3.7/site-packages/tornado/iostream.py\", line 184, in advance\n",
      "    assert 0 < size <= self._size\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layout = neuroglancer.row_layout(\n",
    "        [neuroglancer.LayerGroupViewer(layers=['f61465','atlas_f61465']),\n",
    "         neuroglancer.LayerGroupViewer(layers=['m61468','atlas_m61468'])])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightserv",
   "language": "python",
   "name": "lightserv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
